---
title: "Lecture 4"
output:
  pdf_document: default
---
```{r setup, message = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
set.seed(181818)
```

#Notes and code references 

## Example: discrete inverse transform

Given a probability mass function $p_i = P(X =i), i=1,\ldots,n$, generate the value of a random variable with this probability mass function.

* Existing function:
    ```{r}
    p <- c(0.1, 0.3, 0.6)
    x <- sample(1 : length(p), size = 1, prob = p)
    ```
    
* Inverse transform:
    ```{r}
    p <- c(0.1, 0.3, 0.6)
    u <- runif(1)
    for(i in 1 : length(p))
    {
      if(u < sum(p[1 : i]))
      {
        x <- return(i)
        break
      }
    }
    ```



# Monte Carlo Simulations: Missisippi

## General structure of Monte Carlo simulations

1. Simulate many examples
2. Calculate something on each example
3. Explore the many calculated things

## Example: Missisippi

Consider the 11 letters in the word *Mississippi*.

```{r}
library(tidyverse)
(mi_letters <- str_split("Mississippi", "")[[1]])
```

What is the probability that no adjacent letters are the same, in a random reordering of the letters?

*Taken from Tijms, Henk. Probability: A Lively Introduction. Cambridge University Press, 2017.*


## Mississippi

1. Generate random reorderings of the letters in *Mississippi*
2. For each reordering, ask: are all adjacent letters different?
3. Find the proportion of "Yes"s

## One pretty flexible approach 

First, figure out 1. and 2. on a single example.

Then scale up:

1. Simulate many examples `rerun()`
2. Calculate something on each example `map()`, `map_dbl()`
3. Explore the many calculated things `# depends on goal`

`rerun()` and `map()` are in the purrr package.

## One Mississippi

Step 1: How do we get **a** random reordering of the letters in Mississippi?


```{r}
sample(mi_letters)
```

`sample(x, size, replace = FALSE)`

> sample takes a sample of the specified size from the elements of x using either with or without replacement.

-- `?sample`

```{r}
one_reordering <- sample(mi_letters)
```

## Two Mississippi

Step 2: Given a reordering, does it have letters next to each other that are the same? We want `TRUE` when no adjacent letters match.

The `rle()` function will be very useful.

**What does it do?**
```{r}
one_reordering
rle(one_reordering)
```

**How can we use it?**

Look for any lengths greater than 2.

How do you get out the lengths? Some strategies:
```{r, eval = FALSE}
rle(one_reordering)$lengths # guess

?rle # read the Value section 

rel_one <- rle(one_reordering) # save  
rel_one$lengths # then rely on RStudio completion

# use str()
str(one_reordering)
```

Now find out if any are greater than 1.  My approach:
```{r}
all(rle(one_reordering)$lengths == 1)
```

Some other approaches
```{r, eval = FALSE}
length(rle(one_reordering)$lengths) == length(one_reordering)
!(mean(rle(one_reordering)$lengths) > 1)
max(rle(one_reordering)$lengths) == 1
```

## So far

```{r}
one_reordering <- sample(mi_letters) # One example

# Fill in this bit in class
all(rle(one_reordering)$lengths == 1)
```

## Scaling up - many examples with `rerun()`

The first argument is the number of times you'd like to repeat the evaluation of the second argument.

```{r}
many_reorderings <- rerun(.n = 1000, sample(mi_letters))
```



## Scaling up - for each example, do something with `map()`

`map()` solves iteration problems, like: for each ___ do ___.

1. First argument is the object you want to iterate over, `many_reorderings`

2. Second argument describes what you want to do. One way, specify a formula (starts with `~`) using `.` as a placeholder for a single example:  `~ any(rle(.)$lengths > 1`

```{r, results="hide"}
map(many_reorderings,
  ~ all(rle(.)$lengths == 1))
```

## map() returns a list

Use one of its friends instead: `map_dbl()`, `map_lgl()`, `map_int()`, `map_chr()` to get an atomic vector.



```{r, results = "hide"}
map_lgl(many_reorderings, ~ all(rle(.x)$lengths == 1))
```

## All together

```{r}
num_sims <- 1000
many_reorderings <- rerun(num_sims, sample(mi_letters))
adj_letters_same <- map_lgl(many_reorderings, 
  ~ all(rle(.x)$lengths == 1))

# Explore 
adj_letters_same %>% table()
adj_letters_same %>% mean()
```

# Monte Carlo Simulations: Another Example

A random sequence of H's and T's is generated by tossing a fair coin $n = 20$ times.  What's the expected length of the longest run of consecutive heads or tails?

*Taken from Tijms, Henk. Probability: A Lively Introduction. Cambridge University Press, 2017.*

## Iteration

Common patterns:

1. Do this thing `m` times, `rerun()`
2. Do this thing to each element of `x`, `map()`
3. Do this thing until some condition is satisfied `while`

You can do 1. and 2. with `for` loops, but the purrr functions abstract away the details and let you focus on *"this thing"*.

*(You also don't run the risk of writing an inefficient `for` loop)*

**But remember** R loves working with vectors. Don't iterate over the elements of a vector, when a function exists to handle the whole vector.

## Recap: General Ideas

1. Simulate many examples (`rerun()`)
2. Calculate something on each example (`map()`, `map_dbl()`)
3. Explore the many calculated things (`# depends on goal`)

```{r}
# A single simulated example 1 = H, 0 = T
one_sequence <- rbinom(20, size = 1, prob = 0.5)
```

```{r}
# Longest run?
max(rle(one_sequence)$lengths)
```

All together...
```{r get-longest-runs}
num_sims <- 1000
many_sequences <- rerun(num_sims, 
  rbinom(20, size = 1, prob = 0.5))
longest_runs <- map_dbl(many_sequences, 
  ~ max(rle(.)$lengths))

# Finally...
mean(longest_runs)
```

## Ways things get more complicated

1. The thing you are simulating is complicated.
2. The thing you are calculating is complicated.
3. The thing you are simulating or calculating depends on some parameters and you want to explore how they affect the result.

Solve 1. and 2. by writing functions, 3. with further iteration.

# Functions



```{r}
x <- 1:10

# sd_over_mean
# ratio_function
# cv

# a minimal version
coefficient_of_variation <- function(x){
  sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)
}

# a more complete version
coefficient_of_variation <- function(x, na.rm = FALSE, ...){
  sd(x, na.rm = na.rm) / mean(x, na.rm = na.rm, ...)
}

x <- runif(10)
coefficient_of_variation(x = x)

coefficient_of_variation(x = x, trim = 0.25)
```

## Exponential inverse transform


```{r}
u <- runif(1)
lambda <- 5
(x <- -1 / lambda * log(1 - u))
```



```{r}
u <- runif(1)
lambda <- 5
(x <- -1 / lambda * log(1 - u))

sample_exp <- function(n, lambda){
  u <- runif(n)
  -1 / lambda * log(1 - u)
}

sample_exp(10, lambda = 5)
```

## Continuous inverse transform

What if we wanted this to work for any inverse CDF function?

```{r}
exp_icdf <- function(u, lambda) {-1 / lambda * log(1 - u)}

u <- runif(1)
exp_icdf(u, lambda = 5)

sample_inverse_cdf <- function(n, inv_cdf, ...){
  u <- runif(n)
  inv_cdf(u, ...)
}
sample_inverse_cdf(20, exp_icdf, lambda = 5)
```

#simulate 100 values from a Normal(0, 1). 


```{r}
qnorm(0.5) # can use the built in quantile function 
x <- sample_inverse_cdf(100, qnorm) 
hist(x) # Looks good
```

```{r}
# The `...` allow us to pass in other parameters to our inverse 
# CDF function
x <- sample_inverse_cdf(10000, qnorm, mean = 5) 
hist(x) # Now centered at 5
``` 

